# Llama-3.2-3B-Instruct-uncensored-Q4_K_M_gguf
run with llama cpp
